// services/aiService.js
// ‚úÖ Phi√™n b·∫£n t·ªëi ∆∞u ch√≠nh th·ª©c: x·ª≠ l√Ω Q&A song song (OpenAI + Embedding)
// ‚úÖ ƒê√£ lo·∫°i b·ªè double rate-limit (check quota ch·ªâ c√≤n ·ªü /pages/api/ask.js)
// ‚úÖ T·ªëi ∆∞u log, l·ªói, v√† l∆∞u tr·ªØ song song Firestore + local

import { vectorService } from "./vectorService.js";
import { dbService } from "./dbService.js";
import { openai } from "../lib/openai.js";

/**
 * aiService
 * - Nh·∫≠n c√¢u h·ªèi t·ª´ API (ƒë√£ qua rate-limit check)
 * - T√¨m c√¢u t∆∞∆°ng t·ª± t·ª´ vectorService
 * - N·∫øu kh√¥ng c√≥, g·ªçi OpenAI Q&A + Embedding song song
 * - L∆∞u k·∫øt qu·∫£ ra Firestore v√† local (qua dbService + vectorService)
 */
export const aiService = {
  async processQuestion({ question, userIp, uid = null }) {
    const normalized = question?.trim()?.toLowerCase();
    if (!normalized) throw new Error("C√¢u h·ªèi tr·ªëng ho·∫∑c kh√¥ng h·ª£p l·ªá.");

    console.log(`\n[aiService] üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω c√¢u h·ªèi | IP: ${userIp} | UID: ${uid}`);
    console.log(`[aiService] üî∏ N·ªôi dung: "${normalized}"`);

    console.time("[aiService] total_time");

    try {
      // 1Ô∏è‚É£ Ki·ªÉm tra cache / c√¢u t∆∞∆°ng t·ª±
      let similar = null;
      try {
        similar = await vectorService.findSimilar(normalized);
      } catch (err) {
        console.warn("[aiService] ‚ö†Ô∏è vectorService.findSimilar l·ªói:", err?.message || err);
      }

      if (similar) {
        console.log("[aiService] üß† T√¨m th·∫•y c√¢u t∆∞∆°ng t·ª± trong vector cache.");
        console.timeEnd("[aiService] total_time");
        return { ...similar, source: "vector-cache" };
      }

      // 2Ô∏è‚É£ G·ªçi OpenAI Q&A v√† t·∫°o embedding song song
      console.log("[aiService] üîÑ G·ªçi song song OpenAI (chat + embedding)...");
      const [completion, embeddingRes] = await Promise.allSettled([
        openai.chat.completions.create({
          model: process.env.OPENAI_MODEL || "gpt-4o-mini",
          messages: [{ role: "user", content: normalized }],
        }),
        openai.embeddings.create({
          model: process.env.EMBEDDING_MODEL || "text-embedding-3-small",
          input: normalized,
        }),
      ]);

      // ‚úÖ X·ª≠ l√Ω k·∫øt qu·∫£ Q&A
      let answer = "(Kh√¥ng c√≥ ph·∫£n h·ªìi)";
      if (completion.status === "fulfilled") {
        answer =
          completion.value?.choices?.[0]?.message?.content?.trim() ||
          "(Kh√¥ng c√≥ ph·∫£n h·ªìi)";
        console.log("[aiService] ‚úÖ Nh·∫≠n ph·∫£n h·ªìi t·ª´ OpenAI");
      } else {
        console.error(
          "[aiService] ‚ùå L·ªói g·ªçi OpenAI Chat:",
          completion.reason?.message || completion.reason
        );
      }

      // ‚úÖ X·ª≠ l√Ω k·∫øt qu·∫£ embedding
      let embedding = null;
      if (embeddingRes.status === "fulfilled") {
        embedding = embeddingRes.value?.data?.[0]?.embedding || null;
        console.log("[aiService] ‚úÖ Embedding t·∫°o th√†nh c√¥ng");
      } else {
        console.warn(
          "[aiService] ‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o embedding:",
          embeddingRes.reason?.message || embeddingRes.reason
        );
      }

      // 3Ô∏è‚É£ L∆∞u song song QA + Embedding
      console.log("[aiService] üíæ L∆∞u d·ªØ li·ªáu (QA + embedding) song song...");
      await Promise.allSettled([
        dbService.saveQA({ question: normalized, answer, embedding, userIp, uid }),
        vectorService.saveEmbedding(normalized, embedding),
      ]);

      console.timeEnd("[aiService] total_time");
      return { answer, source: "openai" };

    } catch (err) {
      console.error("[aiService] üí• Pipeline l·ªói:", err?.message || err);
      console.timeEnd("[aiService] total_time");
      throw err;
    }
  },
};

